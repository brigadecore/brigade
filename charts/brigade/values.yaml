## Default values for brigade
## This is a YAML-formatted file.
## Declare variables to be passed into your templates.

rbac:
  ## Indicates whether relevant cluster-scoped roles should be installed/updated
  ## by this chart. Set to false if this is NOT the first install of brigade in
  ## a given cluster, otherwise this chart will attempt to create resources that
  ## already exist.
  installGlobalResources: true

## All settings for the API server
apiserver:

  replicas: 1

  ## Host should be set accurately for a variety of reasons. This is used in
  ## ingress resources, cert generation, and in creating URLs for Open ID
  ## Connect "three legged" authentication.
  host: localhost

  image:
    repository: brigadecore/brigade2-apiserver
    ## tag should only be specified if you want to override Chart.appVersion
    ## The default tag is the value of .Chart.AppVersion
    # tag:
    pullPolicy: IfNotPresent

  rootUser:
    enabled: true

    ## The root user password will be an auto-generated random string when not
    ## supplied. See NOTES.txt after deployment for retrieval steps.
    # password:

    ## Session TTL dictates the default time-to-live for the root user session.
    ## Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
    ## For example, "60s", "2h45m", "168h" (1 week)
    sessionTTL: 1h

  ## Options for authenticating via a third-party authentication provider.
  thirdPartyAuth:
    ## Valid values are "oidc" (for OpenID Connect), "github" (for OAuth2 with
    ## GitHub as the identity provider), or "disabled"
    strategy: disabled
    ## OpenId Connect configuration. Only applicable when thirdPartyAuth == oidc
    ## OpenID Connect support REQUIRES TLS to be enabled.
    oidc:
      ## ProviderURL examples:
      ##
      ##   Google Identity Platform:
      ##     https://accounts.google.com
      ##
      ##   Azure Active Directory: 
      ##     https://login.microsoftonline.com/{tenant id}/v2.0
      ##
      ## Any OpenID Connect provider SHOULD work, but we've tested with those
      ## above.
      # providerURL: ""
      ## The API server uses the client ID and client secret to authenticate
      ## itself to the OpenID Connect identity provider.
      # clientID: ""
      # clientSecret: ""
    github:
      ## The API server uses the client ID and client secret to authenticate
      ## itself to GitHub.
      # clientID: ""
      # clientSecret: ""
      ## GitHub lacks the sophisticated access controls available in identity
      ## platforms like Google Identity Platform and Azure Active Directory--
      ## controls that could be used to limit who can successfully authenticate
      ## to Brigade. Given this, allowedOrganizations below can be used to
      ## enumerate the GitHub organizations whose members are permitted to
      ## authenticate to Brigade. If this list is left commented or empty,
      ## access will not be restricted by organization.
      # allowedOrganizations: []
    ## User Session TTL dictates the default time-to-live for user sessions.
    ## Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
    ## For example, "60s", "2h45m", "168h" (1 week)
    userSessionTTL: 168h
    ## List user IDs from third-party identity provider (email address if using
    ## OpenID Connect or GitHub handle if using GitHub) who will AUTOMATICALLY
    ## be granted system admin permissions the first time they log in. This is
    ## useful for automating post-install setup. Absent this option, one would
    ## have to log in, log out, log back in as root, grant themselves
    ## permissions, then log out, then log back in as themselves.
    admins: []

  tls:
    ## Whether to enable TLS. If true then you MUST do ONE of three things to
    ## ensure the existence of a TLS certificate:
    ##
    ## 1. Set generateSelfSignedCert below to true (the default)
    ## 2. OR Set values for BOTH the cert and key fields below
    ## 3. OR create a cert secret named <Helm release name>-apiserver-cert in
    ##    the same namespace as Brigade. This secret could be created manually
    ##    or through other means, such as a cert manager.
    ##
    ## TLS SHOULD always be enabled, even when ingress is used because other
    ## components within the Kubernetes cluster (e.g. Brigade gateways) will
    ## interact with the apiserver and will not go through the ingress
    ## controller to do so, but SHOULD still interact over a secure connection.
    ## It is advised that this be disabled ONLY if utilizing a service mesh to
    ## enforce secure connections to the apiserver for you.
    enabled: true
    ## Whether to generate a self-signed certificate. If true, a new certificate
    ## will be generated for every revision of the corresponding Helm release.
    ## Since the certificate is self-signed, it will not be trusted by clients
    ## and should absolutely not be used for production, but having this enabled
    ## as a default effectively discourages the more heavy-handed option to
    ## disable TLS entirely. If TLS is enabled and cert generation is DISABLED,
    ## users MUST provide their own cert and private key below OR create a cert
    ## secret named <Helm release name>-apiserver-cert in the same namespace as
    ## Brigade.
    generateSelfSignedCert: true
    # cert: base 64 encoded cert goes here
    # key: base 64 encoded key goes here

  ingress:
    ## Whether to enable ingress. By default, this is disabled. Enabling ingress
    ## is advanced usage.
    enabled: false
    ## Optionally use annotations specified by your ingress controller's
    ## documentation to customize the behavior of the ingress resource.
    annotations:
      # kubernetes.io/ingress.class: nginx
    ## From Kubernetes 1.18+ this field is supported in case your ingress controller supports it.
    ## When set, you do not need to add the ingress class as annotation.
    ingressClassName:
    tls:
      ## Whether to enable TLS. If true then you MUST do ONE of three things to
      ## ensure the existence of a TLS certificate:
      ##
      ## 1. Set generateSelfSignedCert below to true (the default)
      ## 2. OR Set values for BOTH the cert and key fields below
      ## 3. OR create a cert secret named
      ##    <Helm release name>-apiserver-ingress-cert in the same namespace as
      ##    Brigade. This secret could be created manually or through other
      ##    means, such as a cert manager.
      ##
      ## Note there is a wide disparity in the feature set of various ingress
      ## controllers and some ingress controllers may be able to provision a
      ## certificate for you even with TLS disabled here. Consult your ingress
      ## controller's documentation.
      enabled: true
      ## Whether to generate a self-signed certificate. If true, a new
      ## certificate will be generated for every revision of the corresponding
      ## Helm release. Since the certificate is self-signed, it will not be
      ## trusted by clients and should absolutely not be used for production,
      ## but having this enabled as a default effectively discourages the more
      ## heavy-handed option to disable TLS entirely. If ingress TLS is enabled
      ## and cert generation is DISABLED, users MUST provide their own cert and
      ## private key below OR create a cert secret named
      ## <Helm release name>-apiserver-ingres-cert in the same namespace as
      ## Brigade.
      generateSelfSignedCert: true
      # cert: base 64 encoded cert goes here
      # key: base 64 encoded key goes here

  resources: {}
    # We usually recommend not to specify default resources and to leave this as
    # a conscious choice for the user. This also increases chances charts run on
    # environments with little resources, such as Minikube. If you do want to
    # specify resources, uncomment the following lines, adjust them as
    # necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  nodeSelector: {}

  tolerations: []

  service:
    ## If you're not going to use an ingress controller, you may want to change
    ## this value to LoadBalancer for production deployments. If running
    ## locally, you may want to change it to NodePort OR leave it as ClusterIP
    ## and use `kubectl port-forward` to map a port on the local network
    ## interface to the service.
    type: CLusterIP
    ## Host port the service will be mapped to when service type is either
    ## NodePort or LoadBalancer. If not specified, Kubernetes chooses.
    # nodePort:

scheduler:

  image:
    repository: brigadecore/brigade2-scheduler
    ## tag should only be specified if you want to override Chart.appVersion
    ## The default tag is the value of .Chart.AppVersion
    # tag:
    pullPolicy: IfNotPresent

  tls:
    ignoreCertWarnings: true

  scheduling:
    maxConcurrentWorkers: 2
    maxConcurrentJobs: 8

  resources: {}
    # We usually recommend not to specify default resources and to leave this as
    # a conscious choice for the user. This also increases chances charts run on
    # environments with little resources, such as Minikube. If you do want to
    # specify resources, uncomment the following lines, adjust them as
    # necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  nodeSelector: {}

  tolerations: []

observer:

  image:
    repository: brigadecore/brigade2-observer
    ## tag should only be specified if you want to override Chart.appVersion
    ## The default tag is the value of .Chart.AppVersion
    # tag:
    pullPolicy: IfNotPresent

  tls:
    ignoreCertWarnings: true

  config:
    ## maxWorkerLifetime dictates the maximum amount of time that a worker
    ## is permitted to run, assuming no timeout has been set on the worker itself.
    ## (Default is 24 hours)
    ## Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
    ## For example, "60s", "2h45m", "168h" (1 week)
    # maxWorkerLifetime:
    ## maxJobLifetime dictates the maximum amount of time that a job
    ## is permitted to run, assuming no timeout has been set on the job itself.
    ## (Default is 24 hours)
    ## Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
    ## For example, "60s", "2h45m", "168h" (1 week)
    # maxJobLifetime:
    ## delayBeforeCleanup dictates the length of the grace period between when
    ## a worker or job pod completes and when it is permanently cleaned up.
    ## This can be increased in a busy cluster to give log agents a better
    ## chance of capturing all logs before pods are deleted forever. Its also a
    ## useful value to adjust when troubleshooting.
    ## (Default is 1 minute)
    ## Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
    ## For example, "60s", "2h45m", "168h" (1 week)
    # delayBeforeCleanup: 

gitInitializer:

  linux:
    image:
      repository: brigadecore/brigade2-git-initializer
      ## tag should only be specified if you want to override Chart.appVersion
      ## The default tag is the value of .Chart.AppVersion
      # tag:
      pullPolicy: IfNotPresent

  windows:
    image:
      repository: brigadecore/brigade2-git-initializer-windows
      ## tag should only be specified if you want to override Chart.appVersion
      ## The default tag is the value of .Chart.AppVersion
      # tag:
      pullPolicy: IfNotPresent

worker:

  image:
    repository: brigadecore/brigade2-worker
    ## tag should only be specified if you want to override Chart.appVersion
    ## The default tag is the value of .Chart.AppVersion
    # tag:
    pullPolicy: IfNotPresent

  workspaceStorageClass: nfs

  # Optional nodeSelector key/value for all worker and job pods, for scheduling
  # on nodes reserved for Brigade workloads.
  #
  # For more details, see
  # https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
  #
  # Example:
  # nodeSelector:
  #   key: brigadehost
  #   value: true
  # This will match any/all nodes with the 'brigadehost=true' label.
  nodeSelector:
    # key:
    # value:

  # Optional toleration key/value for all worker and job pods, for tolerating
  # (i.e. allowing to schedule on) nodes specifically intended to run Brigade
  # workloads.
  #
  # Notes:
  # If only a key is supplied, the toleration operator field will be set to
  # "Exists", meaning any value is permitted for that key.
  # If both a key and value are supplied, the toleration operator will be set
  # to "Equal", meaning the key and value must match.
  # In either case, the toleration effect field is left empty, matching all
  # effects for the supplied key.
  #
  # For more details, see
  # https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
  #
  # Example:
  # toleration:
  #   key: brigadehost
  # This will allow scheduling an any/all nodes tainted with
  # 'brigadehost=<value>:<effect>', for any value and any effect.
  # (Operator = "Exists")
  #
  # Example:
  # toleration:
  #   key: brigadehost
  #   value: true
  # This will allow scheduling an any/all nodes tainted with
  # 'brigadehost=true:<effect>', for any effect. (Operator = "Equal")
  toleration:
    # key:
    # value:

logger:

  linux:

    image:
      repository: brigadecore/brigade2-logger
      ## tag should only be specified if you want to override Chart.appVersion
      ## The default tag is the value of .Chart.AppVersion
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # We usually recommend not to specify default resources and to leave this
      # as a conscious choice for the user. This also increases chances charts
      # run on environments with little resources, such as Minikube. If you do
      # want to specify resources, uncomment the following lines, adjust them as
      # necessary, and remove the curly braces after 'resources:'.
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
      # requests:
      #   cpu: 100m
      #   memory: 128Mi

    nodeSelector:
      kubernetes.io/os: linux

    tolerations: []

  windows:

    image:
      repository: brigadecore/brigade2-logger-windows
      ## tag should only be specified if you want to override Chart.appVersion
      ## The default tag is the value of .Chart.AppVersion
      # tag:
      pullPolicy: IfNotPresent

    resources: {}
      # We usually recommend not to specify default resources and to leave this
      # as a conscious choice for the user. This also increases chances charts
      # run on environments with little resources, such as Minikube. If you do
      # want to specify resources, uncomment the following lines, adjust them as
      # necessary, and remove the curly braces after 'resources:'.
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
      # requests:
      #   cpu: 100m
      #   memory: 128Mi

    nodeSelector:
      kubernetes.io/os: windows

    tolerations:
    - effect: NoSchedule
      key: os
      operator: Equal
      value: windows

externalMongodb:

  isCosmosdb: false
  connectionString: mongodb://<username>:<password>@<host>:<port>/<database>?<options>
  database: <database>

mongodb:

  enabled: true

  ## @section Global parameters
  ## Global Docker image parameters
  ## Please, note that this will override the image parameters, including dependencies, configured to use the global value
  ## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass
  ##

  ## @param global.imageRegistry Global Docker image registry
  ## @param global.imagePullSecrets Global Docker registry secret names as an array
  ## @param global.storageClass Global StorageClass for Persistent Volume(s)
  ## @param global.namespaceOverride Override the namespace for resource deployed by the chart, but can itself be overridden by the local namespaceOverride
  ##
  global:
    imageRegistry: ""
    ## E.g.
    ## imagePullSecrets:
    ##   - myRegistryKeySecretName
    ##
    imagePullSecrets: []
    storageClass: ""
    namespaceOverride: ""

  ## @section Common parameters
  ##

  ## @param nameOverride String to partially override mongodb.fullname template (will maintain the release name)
  ##
  nameOverride: ""
  ## @param fullnameOverride String to fully override mongodb.fullname template
  ##
  fullnameOverride: ""
  ## @param clusterDomain Default Kubernetes cluster domain
  ##
  clusterDomain: cluster.local
  ## @param extraDeploy Array of extra objects to deploy with the release
  ## extraDeploy:
  ## This needs to be uncommented and added to 'extraDeploy' in order to use the replicaset 'mongo-labeler' sidecar
  ## for dynamically discovering the mongodb primary pod
  ## suggestion is to use a hard-coded and predictable TCP port for the primary mongodb pod (here is 30001, choose your own)
  ## - apiVersion: v1
  ##   kind: Service
  ##   metadata:
  ##     name: mongodb-primary
  ##     namespace: the-mongodb-namespace
  ##     labels:
  ##       app.kubernetes.io/component: mongodb
  ##       app.kubernetes.io/instance: mongodb
  ##       app.kubernetes.io/managed-by: Helm
  ##       app.kubernetes.io/name: mongodb
  ##   spec:
  ##     type: NodePort
  ##     externalTrafficPolicy: Cluster
  ##     ports:
  ##       - name: mongodb
  ##         port: 30001
  ##         nodePort: 30001
  ##         protocol: TCP
  ##         targetPort: mongodb
  ##     selector:
  ##       app.kubernetes.io/component: mongodb
  ##       app.kubernetes.io/instance: mongodb
  ##       app.kubernetes.io/name: mongodb
  ##       primary: "true"
  ##
  extraDeploy: []
  ## @param commonLabels Add labels to all the deployed resources (sub-charts are not considered). Evaluated as a template
  ##
  commonLabels: {}
  ## @param commonAnnotations Common annotations to add to all Mongo resources (sub-charts are not considered). Evaluated as a template
  ##
  commonAnnotations: {}

  ## Enable diagnostic mode in the deployment
  ##
  diagnosticMode:
    ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)
    ##
    enabled: false
    ## @param diagnosticMode.command Command to override all containers in the deployment
    ##
    command:
      - sleep
    ## @param diagnosticMode.args Args to override all containers in the deployment
    ##
    args:
      - infinity

  ## @section MongoDB&reg; parameters
  ##

  ## Bitnami MongoDB&reg; image
  ## ref: https://hub.docker.com/r/bitnami/mongodb/tags/
  ## @param image.registry MongoDB&reg; image registry
  ## @param image.repository MongoDB&reg; image registry
  ## @param image.tag MongoDB&reg; image tag (immutable tags are recommended)
  ## @param image.pullPolicy MongoDB&reg; image pull policy
  ## @param image.pullSecrets Specify docker-registry secret names as an array
  ## @param image.debug Set to true if you would like to see extra information on logs
  ##
  image:
    registry: docker.io
    repository: bitnami/mongodb
    tag: 4.4.10-debian-10-r20
    ## Specify a imagePullPolicy
    ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
    ## Set to true if you would like to see extra information on logs
    ##
    debug: false

  ## @param schedulerName Name of the scheduler (other than default) to dispatch pods
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param architecture MongoDB&reg; architecture (`standalone` or `replicaset`)
  ##
  architecture: standalone
  ## @param useStatefulSet Set to true to use a StatefulSet instead of a Deployment (only when `architecture=standalone`)
  ##
  useStatefulSet: false
  ## MongoDB&reg; Authentication parameters
  ##
  auth:
    ## @param auth.enabled Enable authentication
    ## ref: https://docs.mongodb.com/manual/tutorial/enable-authentication/
    ##
    enabled: true
    ## @param auth.rootUser MongoDB&reg; root user
    ##
    rootUser: root
    ## @param auth.rootPassword MongoDB&reg; root password
    ## ref: https://github.com/bitnami/bitnami-docker-mongodb/blob/master/README.md#setting-the-root-password-on-first-run
    ##
    rootPassword: ""
    ## MongoDB&reg; custom users and databases
    ## ref: https://github.com/bitnami/bitnami-docker-mongodb/blob/master/README.md#creating-users-and-databases-on-first-run
    ## @param auth.usernames List of custom users to be created during the initialization
    ## @param auth.passwords List of passwords for the custom users set at `auth.usernames`
    ## @param auth.databases List of custom databases to be created during the initialization
    ##
    usernames:
    - brigade
    passwords:
    - foobar
    databases:
    - brigade
    ## @param auth.username DEPRECATED: use `auth.usernames` instead
    ## @param auth.password DEPRECATED: use `auth.passwords` instead
    ## @param auth.database DEPRECATED: use `auth.databases` instead
    username: ""
    password: ""
    database: ""
    ## @param auth.replicaSetKey Key used for authentication in the replicaset (only when `architecture=replicaset`)
    ##
    replicaSetKey: ""
    ## @param auth.existingSecret Existing secret with MongoDB&reg; credentials (keys: `mongodb-password`, `mongodb-root-password`, ` mongodb-replica-set-key`)
    ## NOTE: When it's set the previous parameters are ignored.
    ##
    existingSecret: ""
  tls:
    ## @param tls.enabled Enable MongoDB&reg; TLS support between nodes in the cluster as well as between mongo clients and nodes
    ##
    enabled: false
    ## @param tls.autoGenerated Generate a custom CA and self-signed certificates
    ##
    autoGenerated: true
    ## @param tls.existingSecret Existing secret with TLS certificates (keys: `mongodb-ca-cert`, `mongodb-ca-key`, `client-pem`)
    ## NOTE: When it's set it will disable certificate creation
    ##
    existingSecret: ""
    ## Add Custom CA certificate
    ## @param tls.caCert Custom CA certificated (base64 encoded)
    ## @param tls.caKey CA certificate private key (base64 encoded)
    ##
    caCert: ""
    caKey: ""
    ## Bitnami Nginx image
    ## @param tls.image.registry Init container TLS certs setup image registry
    ## @param tls.image.repository Init container TLS certs setup image repository
    ## @param tls.image.tag Init container TLS certs setup image tag (immutable tags are recommended)
    ## @param tls.image.pullPolicy Init container TLS certs setup image pull policy
    ## @param tls.extraDnsNames Add extra dns names to the CA, can solve x509 auth issue for pod clients
    ##
    image:
      registry: docker.io
      repository: bitnami/nginx
      tag: 1.21.3-debian-10-r54
      pullPolicy: IfNotPresent
    ## e.g:
    ## extraDnsNames
    ##   - "DNS.6": "$my_host"
    ##   - "DNS.7": "$test"
    ##
    extraDnsNames: []
  ## @param hostAliases Add deployment host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param replicaSetName Name of the replica set (only when `architecture=replicaset`)
  ## Ignored when mongodb.architecture=standalone
  ##
  replicaSetName: rs0
  ## @param replicaSetHostnames Enable DNS hostnames in the replicaset config (only when `architecture=replicaset`)
  ## Ignored when mongodb.architecture=standalone
  ## Ignored when externalAccess.enabled=true
  ##
  replicaSetHostnames: true
  ## @param enableIPv6 Switch to enable/disable IPv6 on MongoDB&reg;
  ## ref: https://github.com/bitnami/bitnami-docker-mongodb/blob/master/README.md#enabling/disabling-ipv6
  ##
  enableIPv6: false
  ## @param directoryPerDB Switch to enable/disable DirectoryPerDB on MongoDB&reg;
  ## ref: https://github.com/bitnami/bitnami-docker-mongodb/blob/master/README.md#enabling/disabling-directoryperdb
  ##
  directoryPerDB: false
  ## MongoDB&reg; System Log configuration
  ## ref: https://github.com/bitnami/bitnami-docker-mongodb#configuring-system-log-verbosity-level
  ## @param systemLogVerbosity MongoDB&reg; system log verbosity level
  ## @param disableSystemLog Switch to enable/disable MongoDB&reg; system log
  ##
  systemLogVerbosity: 0
  disableSystemLog: false
  ## @param disableJavascript Switch to enable/disable MongoDB&reg; server-side JavaScript execution
  ## ref: https://docs.mongodb.com/manual/core/server-side-javascript/
  ##
  disableJavascript: false
  ## @param enableJournal Switch to enable/disable MongoDB&reg; Journaling
  ## ref: https://docs.mongodb.com/manual/reference/configuration-options/#mongodb-setting-storage.journal.enabled
  ##
  enableJournal: true
  ## @param configuration MongoDB&reg; configuration file to be used for Primary and Secondary nodes
  ## For documentation of all options, see: http://docs.mongodb.org/manual/reference/configuration-options/
  ## Example:
  ## configuration: |-
  ##   # where and how to store data.
  ##   storage:
  ##     dbPath: /bitnami/mongodb/data/db
  ##     journal:
  ##       enabled: true
  ##     directoryPerDB: false
  ##   # where to write logging data
  ##   systemLog:
  ##     destination: file
  ##     quiet: false
  ##     logAppend: true
  ##     logRotate: reopen
  ##     path: /opt/bitnami/mongodb/logs/mongodb.log
  ##     verbosity: 0
  ##   # network interfaces
  ##   net:
  ##     port: 27017
  ##     unixDomainSocket:
  ##       enabled: true
  ##       pathPrefix: /opt/bitnami/mongodb/tmp
  ##     ipv6: false
  ##     bindIpAll: true
  ##   # replica set options
  ##   #replication:
  ##     #replSetName: replicaset
  ##     #enableMajorityReadConcern: true
  ##   # process management options
  ##   processManagement:
  ##      fork: false
  ##      pidFilePath: /opt/bitnami/mongodb/tmp/mongodb.pid
  ##   # set parameter options
  ##   setParameter:
  ##      enableLocalhostAuthBypass: true
  ##   # security options
  ##   security:
  ##     authorization: disabled
  ##     #keyFile: /opt/bitnami/mongodb/conf/keyfile
  ##
  configuration: ""
  ## @param existingConfigmap Name of existing ConfigMap with MongoDB&reg; configuration for Primary and Secondary nodes
  ## NOTE: When it's set the arbiter.configuration parameter is ignored
  ##
  existingConfigmap: ""
  ## @param initdbScripts Dictionary of initdb scripts
  ## Specify dictionary of scripts to be run at first boot
  ## Example:
  ## initdbScripts:
  ##   my_init_script.sh: |
  ##      #!/bin/bash
  ##      echo "Do something."
  ##
  initdbScripts: {}
  ## @param initdbScriptsConfigMap Existing ConfigMap with custom initdb scripts
  ##
  initdbScriptsConfigMap: ""
  ## Command and args for running the container (set to default if not set). Use array form
  ## @param command Override default container command (useful when using custom images)
  ## @param args Override default container args (useful when using custom images)
  ##
  command: []
  args: []
  ## @param extraFlags MongoDB&reg; additional command line flags
  ## Example:
  ## extraFlags:
  ##  - "--wiredTigerCacheSizeGB=2"
  ##
  extraFlags: []
  ## @param extraEnvVars Extra environment variables to add to MongoDB&reg; pods
  ## E.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: BAR
  ##
  extraEnvVars: []
  ## @param extraEnvVarsCM Name of existing ConfigMap containing extra env vars
  ##
  extraEnvVarsCM: ""
  ## @param extraEnvVarsSecret Name of existing Secret containing extra env vars (in case of sensitive data)
  ##
  extraEnvVarsSecret: ""

  ## @section MongoDB&reg; statefulset parameters
  ##

  ## @param annotations Additional labels to be added to the MongoDB&reg; statefulset. Evaluated as a template
  ##
  annotations: {}
  ## @param labels Annotations to be added to the MongoDB&reg; statefulset. Evaluated as a template
  ##
  labels: {}
  ## @param replicaCount Number of MongoDB&reg; nodes (only when `architecture=replicaset`)
  ## Ignored when mongodb.architecture=standalone
  ##
  replicaCount: 2
  ## @param strategyType StrategyType for MongoDB&reg; statefulset
  ## It can be set to RollingUpdate or Recreate by default.
  ##
  strategyType: RollingUpdate
  ## @param podManagementPolicy Pod management policy for MongoDB&reg;
  ## Should be initialized one by one when building the replicaset for the first time
  ##
  podManagementPolicy: OrderedReady
  ## @param podAffinityPreset MongoDB&reg; Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param podAntiAffinityPreset MongoDB&reg; Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param nodeAffinityPreset.type MongoDB&reg; Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param nodeAffinityPreset.key MongoDB&reg; Node label key to match Ignored if `affinity` is set.
    ## E.g.
    ## key: "kubernetes.io/e2e-az-name"
    ##
    key: ""
    ## @param nodeAffinityPreset.values MongoDB&reg; Node label values to match. Ignored if `affinity` is set.
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param affinity MongoDB&reg; Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## Note: podAffinityPreset, podAntiAffinityPreset, and nodeAffinityPreset will be ignored when it's set
  ##
  affinity: {}
  ## @param nodeSelector MongoDB&reg; Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  ## @param tolerations MongoDB&reg; Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param podLabels MongoDB&reg; pod labels
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param podAnnotations MongoDB&reg; Pod annotations
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param priorityClassName Name of the existing priority class to be used by MongoDB&reg; pod(s)
  ## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/
  ##
  priorityClassName: ""
  ## @param runtimeClassName Name of the runtime class to be used by MongoDB&reg; pod(s)
  ## ref: https://kubernetes.io/docs/concepts/containers/runtime-class/
  ##
  runtimeClassName: ""
  ## MongoDB&reg; pods' Security Context.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param podSecurityContext.enabled Enable MongoDB&reg; pod(s)' Security Context
  ## @param podSecurityContext.fsGroup Group ID for the volumes of the MongoDB&reg; pod(s)
  ## @param podSecurityContext.sysctls sysctl settings of the MongoDB&reg; pod(s)'
  ##
  podSecurityContext:
    enabled: true
    fsGroup: 1001
    ## sysctl settings
    ## Example:
    ## sysctls:
    ## - name: net.core.somaxconn
    ##   value: "10000"
    ##
    sysctls: []
  ## MongoDB&reg; containers' Security Context (main and metrics container).
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param containerSecurityContext.enabled Enable MongoDB&reg; container(s)' Security Context
  ## @param containerSecurityContext.runAsUser User ID for the MongoDB&reg; container
  ## @param containerSecurityContext.runAsNonRoot Set MongoDB&reg; container's Security Context runAsNonRoot
  ##
  containerSecurityContext:
    enabled: true
    runAsUser: 1001
    runAsNonRoot: true
  ## MongoDB&reg; containers' resource requests and limits.
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  ## @param resources.limits The resources limits for MongoDB&reg; containers
  ## @param resources.requests The requested resources for MongoDB&reg; containers
  ##
  resources:
    ## Example:
    ## limits:
    ##    cpu: 100m
    ##    memory: 128Mi
    ##
    limits: {}
    ## Examples:
    ## requests:
    ##    cpu: 100m
    ##    memory: 128Mi
    ##
    requests: {}
  ## MongoDB&reg; pods' liveness probe. Evaluated as a template.
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
  ## @param livenessProbe.enabled Enable livenessProbe
  ## @param livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
  ## MongoDB&reg; pods' readiness probe. Evaluated as a template.
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
  ## @param readinessProbe.enabled Enable readinessProbe
  ## @param readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
  ## Slow starting containers can be protected through startup probes
  ## Startup probes are available in Kubernetes version 1.16 and above
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-startup-probes
  ## @param startupProbe.enabled Enable startupProbe
  ## @param startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param startupProbe.periodSeconds Period seconds for startupProbe
  ## @param startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 30
  ## @param customLivenessProbe Override default liveness probe for MongoDB&reg; containers
  ## Ignored when livenessProbe.enabled=true
  ##
  customLivenessProbe: {}
  ## @param customReadinessProbe Override default readiness probe for MongoDB&reg; containers
  ## Ignored when readinessProbe.enabled=true
  ##
  customReadinessProbe: {}
  ## @param customStartupProbe Override default startup probe for MongoDB&reg; containers
  ## Ignored when startupProbe.enabled=true
  ##
  customStartupProbe: {}
  ## @param initContainers Add additional init containers for the hidden node pod(s)
  ## Example:
  ## initContainers:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  initContainers: []
  ## @param sidecars Add additional sidecar containers for the MongoDB&reg; pod(s)
  ## Example:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ## This is an optional 'mongo-labeler' sidecar container that tracks replica-set for the primary mongodb pod
  ## and labels it dynamically with ' primary: "true" ' in order for an extra-deployed service to always expose
  ## and attach to the primary pod, this needs to be uncommented along with the suggested 'extraDeploy' example
  ## and the suggested rbac example for the pod to be allowed adding labels to mongo replica pods
  ## search 'mongo-labeler' through this file to find the sections that needs to be uncommented to make it work
  ##
  ## - name: mongo-labeler
  ##   image: korenlev/k8s-mongo-labeler-sidecar
  ##   imagePullPolicy: Always
  ##   env:
  ##     - name: LABEL_SELECTOR
  ##       value: "app.kubernetes.io/component=mongodb,app.kubernetes.io/instance=mongodb,app.kubernetes.io/name=mongodb"
  ##     - name: NAMESPACE
  ##       value: "the-mongodb-namespace"
  ##     - name: DEBUG
  ##       value: "true"
  ##
  sidecars: []
  ## @param extraVolumeMounts Optionally specify extra list of additional volumeMounts for the MongoDB&reg; container(s)
  ## Examples:
  ## extraVolumeMounts:
  ##   - name: extras
  ##     mountPath: /usr/share/extras
  ##     readOnly: true
  ##
  extraVolumeMounts: []
  ## @param extraVolumes Optionally specify extra list of additional volumes to the MongoDB&reg; statefulset
  ## extraVolumes:
  ##   - name: extras
  ##     emptyDir: {}
  ##
  extraVolumes: []
  ## MongoDB&reg; Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  ##
  pdb:
    ## @param pdb.create Enable/disable a Pod Disruption Budget creation for MongoDB&reg; pod(s)
    ##
    create: false
    ## @param pdb.minAvailable Minimum number/percentage of MongoDB&reg; pods that must still be available after the eviction
    ##
    minAvailable: 1
    ## @param pdb.maxUnavailable Maximum number/percentage of MongoDB&reg; pods that may be made unavailable after the eviction
    ##
    maxUnavailable: ""

  ## @section Traffic exposure parameters
  ##

  ## Service parameters
  ##
  service:
    ## @param service.nameOverride MongoDB&reg; service name
    ##
    nameOverride: ""
    ## @param service.type Kubernetes Service type
    ##
    type: ClusterIP
    ## @param service.port MongoDB&reg; service port
    ##
    port: 27017
    ## @param service.portName MongoDB&reg; service port name
    ##
    portName: mongodb
    ## @param service.nodePort Port to bind to for NodePort and LoadBalancer service types
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
    ##
    nodePort: ""
    ## @param service.clusterIP MongoDB&reg; service cluster IP
    ## e.g:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param service.externalIPs Specify the externalIP value ClusterIP service type.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#external-ips
    ##
    externalIPs: []
    ## @param service.loadBalancerIP loadBalancerIP for MongoDB&reg; Service
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer
    ##
    loadBalancerIP: ""
    ## @param service.loadBalancerSourceRanges Address(es) that are allowed when service is LoadBalancer
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ##
    loadBalancerSourceRanges: []
    ## @param service.annotations Provide any additional annotations that may be required
    ##
    annotations: {}
  ## External Access to MongoDB&reg; nodes configuration
  ##
  externalAccess:
    ## @param externalAccess.enabled Enable Kubernetes external cluster access to MongoDB&reg; nodes (only for replicaset architecture)
    ##
    enabled: false
    ## External IPs auto-discovery configuration
    ## An init container is used to auto-detect LB IPs or node ports by querying the K8s API
    ## Note: RBAC might be required
    ##
    autoDiscovery:
      ## @param externalAccess.autoDiscovery.enabled Enable using an init container to auto-detect external IPs by querying the K8s API
      ##
      enabled: false
      ## Bitnami Kubectl image
      ## ref: https://hub.docker.com/r/bitnami/kubectl/tags/
      ## @param externalAccess.autoDiscovery.image.registry Init container auto-discovery image registry
      ## @param externalAccess.autoDiscovery.image.repository Init container auto-discovery image repository
      ## @param externalAccess.autoDiscovery.image.tag Init container auto-discovery image tag (immutable tags are recommended)
      ## @param externalAccess.autoDiscovery.image.pullPolicy Init container auto-discovery image pull policy
      ## @param externalAccess.autoDiscovery.image.pullSecrets Init container auto-discovery image pull secrets
      ##
      image:
        registry: docker.io
        repository: bitnami/kubectl
        tag: 1.19.16-debian-10-r4
        ## Specify a imagePullPolicy
        ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
        ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
        ##
        pullPolicy: IfNotPresent
        ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)
        ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
        ## Example:
        ## pullSecrets:
        ##   - myRegistryKeySecretName
        ##
        pullSecrets: []
      ## Init Container resource requests and limits
      ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
      ## We usually recommend not to specify default resources and to leave this as a conscious
      ## choice for the user. This also increases chances charts run on environments with little
      ## resources, such as Minikube. If you do want to specify resources, uncomment the following
      ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      ## @param externalAccess.autoDiscovery.resources.limits Init container auto-discovery resource limits
      ## @param externalAccess.autoDiscovery.resources.requests Init container auto-discovery resource requests
      ##
      resources:
        ## Example:
        ## limits:
        ##    cpu: 100m
        ##    memory: 128Mi
        ##
        limits: {}
        ## Examples:
        ## requests:
        ##    cpu: 100m
        ##    memory: 128Mi
        ##
        requests: {}
    ## Parameters to configure K8s service(s) used to externally access MongoDB&reg;
    ## A new service per broker will be created
    ##
    service:
      ## @param externalAccess.service.type Kubernetes Service type for external access. Allowed values: NodePort, LoadBalancer or ClusterIP
      ##
      type: LoadBalancer
      ## @param externalAccess.service.port MongoDB&reg; port used for external access when service type is LoadBalancer
      ##
      port: 27017
      ## @param externalAccess.service.loadBalancerIPs Array of load balancer IPs for MongoDB&reg; nodes
      ## Example:
      ## loadBalancerIPs:
      ##   - X.X.X.X
      ##   - Y.Y.Y.Y
      ##
      loadBalancerIPs: []
      ## @param externalAccess.service.loadBalancerSourceRanges Address(es) that are allowed when service is LoadBalancer
      ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
      ## Example:
      ## loadBalancerSourceRanges:
      ## - 10.10.10.0/24
      ##
      loadBalancerSourceRanges: []
      ## @param externalAccess.service.nodePorts Array of node ports used to configure MongoDB&reg; advertised hostname when service type is NodePort
      ## Example:
      ## nodePorts:
      ##   - 30001
      ##   - 30002
      ##
      nodePorts: []
      ## @param externalAccess.service.domain Domain or external IP used to configure MongoDB&reg; advertised hostname when service type is NodePort
      ## If not specified, the container will try to get the kubernetes node external IP
      ## e.g:
      ## domain: mydomain.com
      ##
      domain: ""
      ## @param externalAccess.service.annotations Service annotations for external access
      ##
      annotations: {}
    ## External Access to MongoDB&reg; Hidden nodes configuration
    ##
    hidden:
      ## @param externalAccess.hidden.enabled Enable Kubernetes external cluster access to MongoDB&reg; hidden nodes
      ##
      enabled: false
      ## Parameters to configure K8s service(s) used to externally access MongoDB&reg;
      ## A new service per broker will be created
      ##
      service:
        ## @param externalAccess.hidden.service.type Kubernetes Service type for external access. Allowed values: NodePort or LoadBalancer
        ##
        type: LoadBalancer
        ## @param externalAccess.hidden.service.port MongoDB&reg; port used for external access when service type is LoadBalancer
        ##
        port: 27017
        ## @param externalAccess.hidden.service.loadBalancerIPs Array of load balancer IPs for MongoDB&reg; nodes
        ## Example:
        ## loadBalancerIPs:
        ##   - X.X.X.X
        ##   - Y.Y.Y.Y
        ##
        loadBalancerIPs: []
        ## @param externalAccess.hidden.service.loadBalancerSourceRanges Address(es) that are allowed when service is LoadBalancer
        ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
        ## Example:
        ## loadBalancerSourceRanges:
        ## - 10.10.10.0/24
        ##
        loadBalancerSourceRanges: []
        ## @param externalAccess.hidden.service.nodePorts Array of node ports used to configure MongoDB&reg; advertised hostname when service type is NodePort. Length must be the same as replicaCount
        ## Example:
        ## nodePorts:
        ##   - 30001
        ##   - 30002
        ##
        nodePorts: []
        ## @param externalAccess.hidden.service.domain Domain or external IP used to configure MongoDB&reg; advertised hostname when service type is NodePort
        ## If not specified, the container will try to get the kubernetes node external IP
        ## e.g:
        ## domain: mydomain.com
        ##
        domain: ""
        ## @param externalAccess.hidden.service.annotations Service annotations for external access
        ##
        annotations: {}

  ## @section Persistence parameters
  ##

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  persistence:
    ## @param persistence.enabled Enable MongoDB&reg; data persistence using PVC
    ##
    enabled: true
    ## @param persistence.existingClaim Provide an existing `PersistentVolumeClaim` (only when `architecture=standalone`)
    ## Requires persistence.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    ## Ignored when mongodb.architecture=replicaset
    ##
    existingClaim: ""
    ## @param persistence.storageClass PVC Storage Class for MongoDB&reg; data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    storageClass: ""
    ## @param persistence.accessModes PV Access Mode
    ##
    accessModes:
      - ReadWriteOnce
    ## @param persistence.size PVC Storage Request for MongoDB&reg; data volume
    ##
    size: 8Gi
    ## @param persistence.annotations PVC annotations
    ##
    annotations: {}
    ## @param persistence.mountPath Path to mount the volume at
    ## MongoDB&reg; images.
    ##
    mountPath: /bitnami/mongodb
    ## @param persistence.subPath Subdirectory of the volume to mount at
    ## and one PV for multiple services.
    ##
    subPath: ""
    ## Fine tuning for volumeClaimTemplates
    ##
    volumeClaimTemplates:
      ## @param persistence.volumeClaimTemplates.selector A label query over volumes to consider for binding (e.g. when using local volumes)
      ## A label query over volumes to consider for binding (e.g. when using local volumes)
      ## See https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#labelselector-v1-meta for more details
      ##
      selector: {}
      ## @param persistence.volumeClaimTemplates.requests Custom PVC requests attributes
      ## Sometime cloud providers use additional requests attributes to provision custom storage instance
      ## See https://cloud.ibm.com/docs/containers?topic=containers-file_storage#file_dynamic_statefulset
      ##
      requests: {}
      ## @param persistence.volumeClaimTemplates.dataSource Add dataSource to the VolumeClaimTemplate
      ##
      dataSource: {}

  ## @section RBAC parameters
  ##

  ## ServiceAccount
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    ## @param serviceAccount.create Enable creation of ServiceAccount for MongoDB&reg; pods
    ##
    create: true
    ## @param serviceAccount.name Name of the created serviceAccount
    ## If not set and create is true, a name is generated using the mongodb.fullname template
    ##
    name: ""
    ## @param serviceAccount.annotations Additional Service Account annotations
    ##
    annotations: {}
  ## Role Based Access
  ## ref: https://kubernetes.io/docs/admin/authorization/rbac/
  ##
  rbac:
    ## @param rbac.create Whether to create & use RBAC resources or not
    ## binding MongoDB&reg; ServiceAccount to a role
    ## that allows MongoDB&reg; pods querying the K8s API
    ## this needs to be set to 'true' to enable the mongo-labeler sidecar primary mongodb discovery
    ##
    create: false
    role:
      ## @param rbac.role.rules Custom rules to create following the role specification
      ## The example below needs to be uncommented to use the 'mongo-labeler' sidecar for dynamic discovery of the primary mongodb pod:
      ## rules:
      ##   - apiGroups:
      ##       - ""
      ##     resources:
      ##       - pods
      ##     verbs:
      ##       - get
      ##       - list
      ##       - watch
      ##       - update
      ##
      rules: []
  ## PodSecurityPolicy configuration
  ## Be sure to also set rbac.create to true, otherwise Role and RoleBinding won't be created.
  ## ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
  ##
  podSecurityPolicy:
    ## @param podSecurityPolicy.create Whether to create a PodSecurityPolicy. WARNING: PodSecurityPolicy is deprecated in Kubernetes v1.21 or later, unavailable in v1.25 or later
    ##
    create: false
    ## @param podSecurityPolicy.allowPrivilegeEscalation Enable privilege escalation
    ## Either use predefined policy with some adjustments or use `podSecurityPolicy.spec`
    ##
    allowPrivilegeEscalation: false
    ## @param podSecurityPolicy.privileged Allow privileged
    ##
    privileged: false
    ## @param podSecurityPolicy.spec Specify the full spec to use for Pod Security Policy
    ## ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
    ## Defining a spec ignores the above values.
    ##
    spec: {}
    ## Example:
    ##    allowPrivilegeEscalation: false
    ##    fsGroup:
    ##      rule: 'MustRunAs'
    ##      ranges:
    ##        - min: 1001
    ##          max: 1001
    ##    hostIPC: false
    ##    hostNetwork: false
    ##    hostPID: false
    ##    privileged: false
    ##    readOnlyRootFilesystem: false
    ##    requiredDropCapabilities:
    ##      - ALL
    ##    runAsUser:
    ##      rule: 'MustRunAs'
    ##      ranges:
    ##        - min: 1001
    ##          max: 1001
    ##    seLinux:
    ##      rule: 'RunAsAny'
    ##    supplementalGroups:
    ##      rule: 'MustRunAs'
    ##      ranges:
    ##        - min: 1001
    ##          max: 1001
    ##    volumes:
    ##      - 'configMap'
    ##      - 'secret'
    ##      - 'emptyDir'
    ##      - 'persistentVolumeClaim'
    ##

  ## @section Volume Permissions parameters
  ##

  ## Init Container parameters
  ## Change the owner and group of the persistent volume(s) mountpoint(s) to 'runAsUser:fsGroup' on each component
  ## values from the securityContext section of the component
  ##
  volumePermissions:
    ## @param volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume(s) mountpoint to `runAsUser:fsGroup`
    ##
    enabled: false
    ## @param volumePermissions.image.registry Init container volume-permissions image registry
    ## @param volumePermissions.image.repository Init container volume-permissions image repository
    ## @param volumePermissions.image.tag Init container volume-permissions image tag (immutable tags are recommended)
    ## @param volumePermissions.image.pullPolicy Init container volume-permissions image pull policy
    ## @param volumePermissions.image.pullSecrets Specify docker-registry secret names as an array
    ##
    image:
      registry: docker.io
      repository: bitnami/bitnami-shell
      tag: 10-debian-10-r239
      ## Specify a imagePullPolicy
      ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
      ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
      ##
      pullPolicy: IfNotPresent
      ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
      ## Example:
      ## pullSecrets:
      ##   - myRegistryKeySecretName
      ##
      pullSecrets: []
    ## Init Container resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## We usually recommend not to specify default resources and to leave this as a conscious
    ## choice for the user. This also increases chances charts run on environments with little
    ## resources, such as Minikube. If you do want to specify resources, uncomment the following
    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    ## @param volumePermissions.resources.limits Init container volume-permissions resource limits
    ## @param volumePermissions.resources.requests Init container volume-permissions resource requests
    ##
    resources:
      ## Example:
      ## limits:
      ##    cpu: 100m
      ##    memory: 128Mi
      ##
      limits: {}
      ## Examples:
      ## requests:
      ##    cpu: 100m
      ##    memory: 128Mi
      ##
      requests: {}
    ## Init container Security Context
    ## Note: the chown of the data folder is done to containerSecurityContext.runAsUser
    ## and not the below volumePermissions.securityContext.runAsUser
    ## When runAsUser is set to special value "auto", init container will try to chwon the
    ## data folder to autodetermined user&group, using commands: `id -u`:`id -G | cut -d" " -f2`
    ## "auto" is especially useful for OpenShift which has scc with dynamic userids (and 0 is not allowed).
    ## You may want to use this volumePermissions.securityContext.runAsUser="auto" in combination with
    ## podSecurityContext.enabled=false,containerSecurityContext.enabled=false and shmVolume.chmod.enabled=false
    ## @param volumePermissions.securityContext.runAsUser User ID for the volumePermissions container
    ##
    securityContext:
      runAsUser: 0

  ## @section Arbiter parameters
  ##

  arbiter:
    ## @param arbiter.enabled Enable deploying the arbiter
    ##   https://docs.mongodb.com/manual/tutorial/add-replica-set-arbiter/
    ##
    enabled: true
    ## @param arbiter.configuration Arbiter configuration file to be used
    ##   http://docs.mongodb.org/manual/reference/configuration-options/
    ##
    configuration: ""
    ## @param arbiter.hostAliases Add deployment host aliases
    ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
    ##
    hostAliases: []
    ## @param arbiter.existingConfigmap Name of existing ConfigMap with Arbiter configuration
    ## NOTE: When it's set the arbiter.configuration parameter is ignored
    ##
    existingConfigmap: ""
    ## Command and args for running the container (set to default if not set). Use array form
    ## @param arbiter.command Override default container command (useful when using custom images)
    ## @param arbiter.args Override default container args (useful when using custom images)
    ##
    command: []
    args: []
    ## @param arbiter.extraFlags Arbiter additional command line flags
    ## Example:
    ## extraFlags:
    ##  - "--wiredTigerCacheSizeGB=2"
    ##
    extraFlags: []
    ## @param arbiter.extraEnvVars Extra environment variables to add to Arbiter pods
    ## E.g:
    ## extraEnvVars:
    ##   - name: FOO
    ##     value: BAR
    ##
    extraEnvVars: []
    ## @param arbiter.extraEnvVarsCM Name of existing ConfigMap containing extra env vars
    ##
    extraEnvVarsCM: ""
    ## @param arbiter.extraEnvVarsSecret Name of existing Secret containing extra env vars (in case of sensitive data)
    ##
    extraEnvVarsSecret: ""
    ## @param arbiter.annotations Additional labels to be added to the Arbiter statefulset
    ##
    annotations: {}
    ## @param arbiter.labels Annotations to be added to the Arbiter statefulset
    ##
    labels: {}
    ## @param arbiter.podAffinityPreset Arbiter Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAffinityPreset: ""
    ## @param arbiter.podAntiAffinityPreset Arbiter Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAntiAffinityPreset: soft
    ## Node affinity preset
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
    ##
    nodeAffinityPreset:
      ## @param arbiter.nodeAffinityPreset.type Arbiter Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
      ##
      type: ""
      ## @param arbiter.nodeAffinityPreset.key Arbiter Node label key to match Ignored if `affinity` is set.
      ## E.g.
      ## key: "kubernetes.io/e2e-az-name"
      ##
      key: ""
      ## @param arbiter.nodeAffinityPreset.values Arbiter Node label values to match. Ignored if `affinity` is set.
      ## E.g.
      ## values:
      ##   - e2e-az1
      ##   - e2e-az2
      ##
      values: []
    ## @param arbiter.affinity Arbiter Affinity for pod assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ## Note: arbiter.podAffinityPreset, arbiter.podAntiAffinityPreset, and arbiter.nodeAffinityPreset will be ignored when it's set
    ##
    affinity: {}
    ## @param arbiter.nodeSelector Arbiter Node labels for pod assignment
    ## ref: https://kubernetes.io/docs/user-guide/node-selection/
    ##
    nodeSelector: {}
    ## @param arbiter.tolerations Arbiter Tolerations for pod assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    ## @param arbiter.podLabels Arbiter pod labels
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
    ##
    podLabels: {}
    ## @param arbiter.podAnnotations Arbiter Pod annotations
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
    ##
    podAnnotations: {}
    ## @param arbiter.priorityClassName Name of the existing priority class to be used by Arbiter pod(s)
    ## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/
    ##
    priorityClassName: ""
    ## @param arbiter.runtimeClassName Name of the runtime class to be used by Arbiter pod(s)
    ## ref: https://kubernetes.io/docs/concepts/containers/runtime-class/
    ##
    runtimeClassName: ""
    ## MongoDB&reg; Arbiter pods' Security Context.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param arbiter.podSecurityContext.enabled Enable Arbiter pod(s)' Security Context
    ## @param arbiter.podSecurityContext.fsGroup Group ID for the volumes of the Arbiter pod(s)
    ## @param arbiter.podSecurityContext.sysctls sysctl settings of the Arbiter pod(s)'
    ##
    podSecurityContext:
      enabled: true
      fsGroup: 1001
      ## sysctl settings
      ## Example:
      ## sysctls:
      ## - name: net.core.somaxconn
      ##   value: "10000"
      ##
      sysctls: []
    ## MongoDB&reg; Arbiter containers' Security Context (only main container).
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
    ## @param arbiter.containerSecurityContext.enabled Enable Arbiter container(s)' Security Context
    ## @param arbiter.containerSecurityContext.runAsUser User ID for the Arbiter container
    ##
    containerSecurityContext:
      enabled: true
      runAsUser: 1001
    ## MongoDB&reg; Arbiter containers' resource requests and limits.
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## We usually recommend not to specify default resources and to leave this as a conscious
    ## choice for the user. This also increases chances charts run on environments with little
    ## resources, such as Minikube. If you do want to specify resources, uncomment the following
    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    ## @param arbiter.resources.limits The resources limits for Arbiter containers
    ## @param arbiter.resources.requests The requested resources for Arbiter containers
    ##
    resources:
      ## Example:
      ## limits:
      ##    cpu: 100m
      ##    memory: 128Mi
      ##
      limits: {}
      ## Examples:
      ## requests:
      ##    cpu: 100m
      ##    memory: 128Mi
      ##
      requests: {}
    ## MongoDB&reg; Arbiter pods' liveness probe. Evaluated as a template.
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
    ## @param arbiter.livenessProbe.enabled Enable livenessProbe
    ## @param arbiter.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
    ## @param arbiter.livenessProbe.periodSeconds Period seconds for livenessProbe
    ## @param arbiter.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    ## @param arbiter.livenessProbe.failureThreshold Failure threshold for livenessProbe
    ## @param arbiter.livenessProbe.successThreshold Success threshold for livenessProbe
    ##
    livenessProbe:
      enabled: true
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 6
      successThreshold: 1
    ## MongoDB&reg; Arbiter pods' readiness probe. Evaluated as a template.
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
    ## @param arbiter.readinessProbe.enabled Enable readinessProbe
    ## @param arbiter.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
    ## @param arbiter.readinessProbe.periodSeconds Period seconds for readinessProbe
    ## @param arbiter.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    ## @param arbiter.readinessProbe.failureThreshold Failure threshold for readinessProbe
    ## @param arbiter.readinessProbe.successThreshold Success threshold for readinessProbe
    ##
    readinessProbe:
      enabled: true
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 6
      successThreshold: 1
    ## @param arbiter.customLivenessProbe Override default liveness probe for Arbiter containers
    ## Ignored when arbiter.livenessProbe.enabled=true
    ##
    customLivenessProbe: {}
    ## @param arbiter.customReadinessProbe Override default readiness probe for Arbiter containers
    ## Ignored when arbiter.readinessProbe.enabled=true
    ##
    customReadinessProbe: {}
    ## @param arbiter.initContainers Add additional init containers for the Arbiter pod(s)
    ## Example:
    ## initContainers:
    ##   - name: your-image-name
    ##     image: your-image
    ##     imagePullPolicy: Always
    ##     ports:
    ##       - name: portname
    ##         containerPort: 1234
    ##
    initContainers: []
    ## @param arbiter.sidecars Add additional sidecar containers for the Arbiter pod(s)
    ## Example:
    ## sidecars:
    ##   - name: your-image-name
    ##     image: your-image
    ##     imagePullPolicy: Always
    ##     ports:
    ##       - name: portname
    ##         containerPort: 1234
    ##
    sidecars: []
    ## @param arbiter.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Arbiter container(s)
    ## Examples:
    ## extraVolumeMounts:
    ##   - name: extras
    ##     mountPath: /usr/share/extras
    ##     readOnly: true
    ##
    extraVolumeMounts: []
    ## @param arbiter.extraVolumes Optionally specify extra list of additional volumes to the Arbiter statefulset
    ## extraVolumes:
    ##   - name: extras
    ##     emptyDir: {}
    ##
    extraVolumes: []
    ## MongoDB&reg; Arbiter Pod Disruption Budget configuration
    ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
    ##
    pdb:
      ## @param arbiter.pdb.create Enable/disable a Pod Disruption Budget creation for Arbiter pod(s)
      ##
      create: false
      ## @param arbiter.pdb.minAvailable Minimum number/percentage of Arbiter pods that should remain scheduled
      ##
      minAvailable: 1
      ## @param arbiter.pdb.maxUnavailable Maximum number/percentage of Arbiter pods that may be made unavailable
      ##
      maxUnavailable: ""
    ## MongoDB&reg; Arbiter service parameters
    ##
    service:
      ## @param arbiter.service.nameOverride The arbiter service name
      ##
      nameOverride: ""

  ## @section Hidden Node parameters
  ##

  hidden:
    ## @param hidden.enabled Enable deploying the hidden nodes
    ##   https://docs.mongodb.com/manual/tutorial/configure-a-hidden-replica-set-member/
    ##
    enabled: false
    ## @param hidden.configuration Hidden node configuration file to be used
    ##   http://docs.mongodb.org/manual/reference/configuration-options/
    ##
    configuration: ""
    ## @param hidden.existingConfigmap Name of existing ConfigMap with Hidden node configuration
    ## NOTE: When it's set the hidden.configuration parameter is ignored
    ##
    existingConfigmap: ""
    ## Command and args for running the container (set to default if not set). Use array form
    ## @param hidden.command Override default container command (useful when using custom images)
    ## @param hidden.args Override default container args (useful when using custom images)
    ##
    command: []
    args: []
    ## @param hidden.extraFlags Hidden node additional command line flags
    ## Example:
    ## extraFlags:
    ##  - "--wiredTigerCacheSizeGB=2"
    ##
    extraFlags: []
    ## @param hidden.extraEnvVars Extra environment variables to add to Hidden node pods
    ## E.g:
    ## extraEnvVars:
    ##   - name: FOO
    ##     value: BAR
    ##
    extraEnvVars: []
    ## @param hidden.extraEnvVarsCM Name of existing ConfigMap containing extra env vars
    ##
    extraEnvVarsCM: ""
    ## @param hidden.extraEnvVarsSecret Name of existing Secret containing extra env vars (in case of sensitive data)
    ##
    extraEnvVarsSecret: ""
    ## @param hidden.annotations Additional labels to be added to thehidden node statefulset
    ##
    annotations: {}
    ## @param hidden.labels Annotations to be added to the hidden node statefulset
    ##
    labels: {}
    ## @param hidden.replicaCount Number of hidden nodes (only when `architecture=replicaset`)
    ## Ignored when mongodb.architecture=standalone
    ##
    replicaCount: 1
    ## @param hidden.strategyType StrategyType for hidden node statefulset
    ## It can be set to RollingUpdate or Recreate by default.
    ##
    strategyType: RollingUpdate
    ## @param hidden.podManagementPolicy Pod management policy for hidden node
    ##
    podManagementPolicy: OrderedReady
    ## @param hidden.podAffinityPreset Hidden node Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAffinityPreset: ""
    ## @param hidden.podAntiAffinityPreset Hidden node Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAntiAffinityPreset: soft
    ## Node affinity preset
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
    ## Allowed values: soft, hard
    ##
    nodeAffinityPreset:
      ## @param hidden.nodeAffinityPreset.type Hidden Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
      ##
      type: ""
      ## @param hidden.nodeAffinityPreset.key Hidden Node label key to match Ignored if `affinity` is set.
      ## E.g.
      ## key: "kubernetes.io/e2e-az-name"
      ##
      key: ""
      ## @param hidden.nodeAffinityPreset.values Hidden Node label values to match. Ignored if `affinity` is set.
      ## E.g.
      ## values:
      ##   - e2e-az1
      ##   - e2e-az2
      ##
      values: []
    ## @param hidden.affinity Hidden node Affinity for pod assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ## Note: podAffinityPreset, podAntiAffinityPreset, and nodeAffinityPreset will be ignored when it's set
    ##
    affinity: {}
    ## @param hidden.nodeSelector Hidden node Node labels for pod assignment
    ## ref: https://kubernetes.io/docs/user-guide/node-selection/
    ##
    nodeSelector: {}
    ## @param hidden.tolerations Hidden node Tolerations for pod assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    ## @param hidden.podLabels Hidden node pod labels
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
    ##
    podLabels: {}
    ## @param hidden.podAnnotations Hidden node Pod annotations
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
    ##
    podAnnotations: {}
    ## @param hidden.priorityClassName Name of the existing priority class to be used by hidden node pod(s)
    ## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/
    ##
    priorityClassName: ""
    ## @param hidden.runtimeClassName Name of the runtime class to be used by hidden node pod(s)
    ## ref: https://kubernetes.io/docs/concepts/containers/runtime-class/
    ##
    runtimeClassName: ""
    ## MongoDB&reg; Hidden containers' resource requests and limits.
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## We usually recommend not to specify default resources and to leave this as a conscious
    ## choice for the user. This also increases chances charts run on environments with little
    ## resources, such as Minikube. If you do want to specify resources, uncomment the following
    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    ## @param hidden.resources.limits The resources limits for hidden node containers
    ## @param hidden.resources.requests The requested resources for hidden node containers
    ##
    resources:
      ## Example:
      ## limits:
      ##    cpu: 100m
      ##    memory: 128Mi
      ##
      limits: {}
      ## Examples:
      ## requests:
      ##    cpu: 100m
      ##    memory: 128Mi
      ##
      requests: {}
    ## MongoDB&reg; Hidden pods' liveness probe. Evaluated as a template.
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
    ## @param hidden.livenessProbe.enabled Enable livenessProbe
    ## @param hidden.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
    ## @param hidden.livenessProbe.periodSeconds Period seconds for livenessProbe
    ## @param hidden.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    ## @param hidden.livenessProbe.failureThreshold Failure threshold for livenessProbe
    ## @param hidden.livenessProbe.successThreshold Success threshold for livenessProbe
    ##
    livenessProbe:
      enabled: true
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 6
      successThreshold: 1
    ## MongoDB&reg; Hidden pods' readiness probe. Evaluated as a template.
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
    ## @param hidden.readinessProbe.enabled Enable readinessProbe
    ## @param hidden.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
    ## @param hidden.readinessProbe.periodSeconds Period seconds for readinessProbe
    ## @param hidden.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    ## @param hidden.readinessProbe.failureThreshold Failure threshold for readinessProbe
    ## @param hidden.readinessProbe.successThreshold Success threshold for readinessProbe
    ##
    readinessProbe:
      enabled: true
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 6
      successThreshold: 1
    ## @param hidden.customLivenessProbe Override default liveness probe for hidden node containers
    ## Ignored when livenessProbe.enabled=true
    ##
    customLivenessProbe: {}
    ## @param hidden.customReadinessProbe Override default readiness probe for hidden node containers
    ## Ignored when readinessProbe.enabled=true
    ##
    customReadinessProbe: {}
    ## @param hidden.initContainers Add init containers to the MongoDB&reg; Hidden pods.
    ## Example:
    ## initContainers:
    ##   - name: your-image-name
    ##     image: your-image
    ##     imagePullPolicy: Always
    ##     ports:
    ##       - name: portname
    ##         containerPort: 1234
    ##
    initContainers: []
    ## @param hidden.sidecars Add additional sidecar containers for the hidden node pod(s)
    ## Example:
    ## sidecars:
    ##   - name: your-image-name
    ##     image: your-image
    ##     imagePullPolicy: Always
    ##     ports:
    ##       - name: portname
    ##         containerPort: 1234
    ##
    sidecars: []
    ## @param hidden.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the hidden node container(s)
    ## Examples:
    ## extraVolumeMounts:
    ##   - name: extras
    ##     mountPath: /usr/share/extras
    ##     readOnly: true
    ##
    extraVolumeMounts: []
    ## @param hidden.extraVolumes Optionally specify extra list of additional volumes to the hidden node statefulset
    ## extraVolumes:
    ##   - name: extras
    ##     emptyDir: {}
    ##
    extraVolumes: []
    ## MongoDB&reg; Hidden Pod Disruption Budget configuration
    ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
    ##
    pdb:
      ## @param hidden.pdb.create Enable/disable a Pod Disruption Budget creation for hidden node pod(s)
      ##
      create: false
      ## @param hidden.pdb.minAvailable Minimum number/percentage of hidden node pods that should remain scheduled
      ##
      minAvailable: 1
      ## @param hidden.pdb.maxUnavailable Maximum number/percentage of hidden node pods that may be made unavailable
      ##
      maxUnavailable: ""
    ## Enable persistence using Persistent Volume Claims
    ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    persistence:
      ## @param hidden.persistence.enabled Enable hidden node data persistence using PVC
      ##
      enabled: true
      ## @param hidden.persistence.storageClass PVC Storage Class for hidden node data volume
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ## set, choosing the default provisioner.
      ##
      storageClass: ""
      ## @param hidden.persistence.accessModes PV Access Mode
      ##
      accessModes:
        - ReadWriteOnce
      ## @param hidden.persistence.size PVC Storage Request for hidden node data volume
      ##
      size: 8Gi
      ## @param hidden.persistence.annotations PVC annotations
      ##
      annotations: {}
      ## @param hidden.persistence.mountPath The path the volume will be mounted at, useful when using different MongoDB&reg; images.
      ##
      mountPath: /bitnami/mongodb
      ## @param hidden.persistence.subPath The subdirectory of the volume to mount to, useful in dev environments
      ## and one PV for multiple services.
      ##
      subPath: ""
      ## Fine tuning for volumeClaimTemplates
      ##
      volumeClaimTemplates:
        ## @param hidden.persistence.volumeClaimTemplates.selector A label query over volumes to consider for binding (e.g. when using local volumes)
        ## See https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#labelselector-v1-meta for more details
        ##
        selector: {}
        ## @param hidden.persistence.volumeClaimTemplates.dataSource Set volumeClaimTemplate dataSource
        ##
        dataSource: {}

  ## @section Metrics parameters
  ##

  metrics:
    ## @param metrics.enabled Enable using a sidecar Prometheus exporter
    ##
    enabled: false
    ## Bitnami MongoDB&reg; Promtheus Exporter image
    ## ref: https://hub.docker.com/r/bitnami/mongodb-exporter/tags/
    ## @param metrics.image.registry MongoDB&reg; Prometheus exporter image registry
    ## @param metrics.image.repository MongoDB&reg; Prometheus exporter image repository
    ## @param metrics.image.tag MongoDB&reg; Prometheus exporter image tag (immutable tags are recommended)
    ## @param metrics.image.pullPolicy MongoDB&reg; Prometheus exporter image pull policy
    ## @param metrics.image.pullSecrets Specify docker-registry secret names as an array
    ##
    image:
      registry: docker.io
      repository: bitnami/mongodb-exporter
      tag: 0.11.2-debian-10-r327
      pullPolicy: IfNotPresent
      ## Optionally specify an array of imagePullSecrets.
      ## Secrets must be manually created in the namespace.
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
      ## e.g:
      ## pullSecrets:
      ##   - myRegistryKeySecretName
      ##
      pullSecrets: []

    ## @param metrics.username String with username for the metrics exporter
    ## If undefined the root user will be used for the metrics exporter
    username: ""
    ## @param metrics.password String with password for the metrics exporter
    ## If undefined but metrics.username is defined, a random password will be generated
    password: ""
    ## @param metrics.extraFlags String with extra flags to the metrics exporter
    ## ref: https://github.com/percona/mongodb_exporter/blob/master/mongodb_exporter.go
    ##
    extraFlags: ""
    ## @param metrics.extraUri Additional URI options of the metrics service
    ## ref: https://docs.mongodb.com/manual/reference/connection-string
    ##
    extraUri: ""
    ## Metrics exporter container resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## We usually recommend not to specify default resources and to leave this as a conscious
    ## choice for the user. This also increases chances charts run on environments with little
    ## resources, such as Minikube. If you do want to specify resources, uncomment the following
    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    ## @param metrics.resources.limits The resources limits for Prometheus exporter containers
    ## @param metrics.resources.requests The requested resources for Prometheus exporter containers
    ##
    resources:
      ## Example:
      ## limits:
      ##    cpu: 100m
      ##    memory: 128Mi
      ##
      limits: {}
      ## Examples:
      ## requests:
      ##    cpu: 100m
      ##    memory: 128Mi
      ##
      requests: {}
    ## @param metrics.containerPort Port of the Prometheus metrics container
    ##
    containerPort: 9216
    ## Prometheus Exporter service configuration
    ##
    service:
      ## @param metrics.service.annotations [object] Annotations for Prometheus Exporter pods. Evaluated as a template.
      ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
      ##
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "{{ .Values.metrics.service.port }}"
        prometheus.io/path: "/metrics"
      ## @param metrics.service.type Type of the Prometheus metrics service
      ##
      type: ClusterIP
      ## @param metrics.service.port Port of the Prometheus metrics service
      ##
      port: 9216
    ## Metrics exporter liveness probe
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes)
    ## @param metrics.livenessProbe.enabled Enable livenessProbe
    ## @param metrics.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
    ## @param metrics.livenessProbe.periodSeconds Period seconds for livenessProbe
    ## @param metrics.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
    ## @param metrics.livenessProbe.failureThreshold Failure threshold for livenessProbe
    ## @param metrics.livenessProbe.successThreshold Success threshold for livenessProbe
    ##
    livenessProbe:
      enabled: true
      initialDelaySeconds: 15
      periodSeconds: 5
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
    ## Metrics exporter readiness probe
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes)
    ## @param metrics.readinessProbe.enabled Enable readinessProbe
    ## @param metrics.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
    ## @param metrics.readinessProbe.periodSeconds Period seconds for readinessProbe
    ## @param metrics.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
    ## @param metrics.readinessProbe.failureThreshold Failure threshold for readinessProbe
    ## @param metrics.readinessProbe.successThreshold Success threshold for readinessProbe
    ##
    readinessProbe:
      enabled: true
      initialDelaySeconds: 5
      periodSeconds: 5
      timeoutSeconds: 1
      failureThreshold: 3
      successThreshold: 1
    ## Prometheus Service Monitor
    ## ref: https://github.com/coreos/prometheus-operator
    ##      https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md
    ##
    serviceMonitor:
      ## @param metrics.serviceMonitor.enabled Create ServiceMonitor Resource for scraping metrics using Prometheus Operator
      ##
      enabled: false
      ## @param metrics.serviceMonitor.namespace Namespace which Prometheus is running in
      ##
      namespace: ""
      ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped
      ##
      interval: 30s
      ## @param metrics.serviceMonitor.scrapeTimeout Specify the timeout after which the scrape is ended
      ## e.g:
      ## scrapeTimeout: 30s
      ##
      scrapeTimeout: ""
      ## @param metrics.serviceMonitor.relabellings RelabelConfigs to apply to samples before scraping.
      ##
      relabellings: []
      ## @param metrics.serviceMonitor.metricRelabelings MetricsRelabelConfigs to apply to samples before ingestion.
      ##
      metricRelabelings: []
      ## @param metrics.serviceMonitor.additionalLabels Used to pass Labels that are used by the Prometheus installed in your cluster to select Service Monitors to work with
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
      ##
      additionalLabels: {}
    ## Custom PrometheusRule to be defined
    ## ref: https://github.com/coreos/prometheus-operator#customresourcedefinitions
    ##
    prometheusRule:
      ## @param metrics.prometheusRule.enabled Set this to true to create prometheusRules for Prometheus operator
      ##
      enabled: false
      ## @param metrics.prometheusRule.additionalLabels Additional labels that can be used so prometheusRules will be discovered by Prometheus
      ##
      additionalLabels: {}
      ## @param metrics.prometheusRule.namespace Namespace where prometheusRules resource should be created
      ##
      namespace: ""
      ## @param metrics.prometheusRule.rules Rules to be created, check values for an example
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#rulegroup
      ##      https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/
      ##
      ## This is an example of a rule, you should add the below code block under the "rules" param, removing the brackets
      ## - name: example
      ##   rules:
      ##   - alert: HighRequestLatency
      ##     expr: job:request_latency_seconds:mean5m{job="myjob"} > 0.5
      ##     for: 10m
      ##     labels:
      ##       severity: page
      ##     annotations:
      ##       summary: High request latency
      ##
      rules: {}

artemis:

  ## It is recommended NOT to scale Artemis beyond a single node. While
  ## Brigade's architecture can tolerate queues distributed across multiple
  ## nodes, it also derives no specific benefit from that topology. This being
  ## the case, there is a benefit to using only a single Artemis node-- namely
  ## that non-distributed queues are guaranteed to be properly FIFO, whilst no
  ## such guarantee can be made with respect to distributed queues. Using a
  ## single node therefore results in improved fairness in scheduling.
  ##
  ## The option to scale beyond a single node is preserved to account for
  ## operators who may eventually transition to an EXTERNAL AMQP 1.0 message
  ## broker that uses distributed queues and who may wish to experiment with
  ## such a configuration in advance.
  replicas: 1

  image:
    repository: brigadecore/brigade2-artemis
    ## tag should only be specified if you want to override Chart.appVersion
    ## The default tag is the value of .Chart.AppVersion
    # tag:
    pullPolicy: IfNotPresent

  username: brigade
  ## The password will be an auto-generated random string when not
  ## supplied. See NOTES.txt after deployment for retrieval steps.
  # password:

  ## Persist data to a volume
  persistence:
    enabled: true
    ## If undefined, the cluster's default storage class is used
    # storageClass:
    accessMode: ReadWriteOnce
    size: 8Gi

  ## Whether to run in a highly available configuration. This would be a good
  ## idea in a production environment, but shouldn't be needed otherwise.
  ha:
    enabled: false
    ## Valid values are "hard" and "soft"
    antiAffinity: soft

  resources: {}
    ## We usually recommend not to specify default resources and to leave this
    ## as a conscious choice for the user. This also increases chances charts
    ## run on environments with little resources, such as Minikube. If you do
    ## want to specify resources, uncomment the following lines, adjust them as
    ## necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  nodeSelector: {}

  tolerations: []

  service:
    type: NodePort

externalAMQP:
  address:
  username:
  password:

azureServiceBus:
  address:
  username:
  password:
